---
title: "DATA 607 Project 3 Analysis"
author: "Susanna Wong"
date: "2023-03-15"
output:
  html_document:
    theme: cerulean
    code_folding: hide
    toc: true
    toc_float: true
editor_options: 
  markdown: 
    wrap: sentence
---

# Introduction
The goal of the project is to use data to answer the question, "Which are the most valued data science skills?".
We web scrap a major job search engine (ex: Indeed, Linkedin, Glassdoor, etc) for job postings.
Create a large csv file that contains the job title, job URL, company name, job salary, and job description.
Then, we will create a list of technical skills, and soft skills, and find the top 5 most frequent technical skills and soft skills on the job postings.
The most valued data science skills are the skills that appear most often on job postings.

# Acquiring the data

We webscrap job postings from LinkedIn using Octoparse. 
```{r}
library(stringr)
tidied_Linkedin <- read.csv('https://raw.githubusercontent.com/suswong/DATA-607-Project-3/main/tidied_Linkedin_version4.csv')
#colnames(tidied_Linkedin)
```

# Tidying the Dataset

# Analysis
## Search {.tabset}
We used a loop that creates a new column for each skill and return a "1" or "0" for each row (job posting). It returns a "1" if the skill is present in the "Job_description" column, and "0" if the skill is not in the column.

### General Skills
https://towardsdatascience.com/top-20-skills-and-keywords-for-data-science-6bc6bfc8c28a
```{r}
general_skills <- tidied_Linkedin[c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description')]

general <- c("(?i)Statistical analysis","(?i)Machine Learning","(?i)data visual","(?i)wrangling","(?i)mathematics","(?i)programming|scripting language","(?i)statistics","(?i)big data","(?i)Artificial intelligence|\\bAI\\b","(?i)Deep learning","(?i)data modeling","(?i)data processing","(?i)data mananagement","(?i)data manipulation","(?i)database","(?i)data architecture","(?i)data mining","(?i)research","(?i)modeling","(?i)analysis","(?i)cloud computing")

for(i in general){
  general_skills[i] <- +str_detect(apply(general_skills, 1, paste0, collapse = " ", ignore_case = TRUE), general[which(general == i)])
}

# colnames(general_skills)
colnames(general_skills) <- c("Job_title", "Company", "Job_location_City", "Job_location_State","Seniority_level", "Employment_type","Job_function","Industries",                 "Job_description","Statistical analysis","Machine Learning","data visual","wrangling","mathematics","programming|scripting language","statistics","big data","Artificial intelligence","Deep learning","data modeling","data processing","data mananagement","data manipulation","database","data architecture","data mining","research","modeling","analysis","cloud computing")

```

### Techincal Skills

```{r}
technical_skills <- tidied_Linkedin[c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description')]

technical <- c("(?i)spss","(?i)stata", "(?i)sas","(?i)scala","(?i)matlab", "(?i)\\bC\\b","(?i)\\bC++\\b", "(?i)Swift", "(?i)Julia","(?i)Hadoop","(?i)Spark","(?i)Pig","(?i)Tableau","(?i)REDCap", "(?i)Qualtrics", "(?i)Power BI", "(?i)Dedoose", "(?i)Atlas TI", "(?i)NVivo", "(?i)MPlus", "(?i)Mixor", "(?i)dbt", "(?i)BigQuery|big query", "(?i)Superset", "(?i)Baseten", "(?i)Airflow","(?i)ETL/ELT pipelines","(?i)Google Analytics", "(?i)Parse.ly", "(?i)Chartbeat","(?i)Excel", "(?i)Plotly", "(?i)Google Data Studio", "(?i)Looker","(?i)Spotfire","(?i)Smartsheet","(?i)\\bBI\\b|Business Intelligence","(?i)C#|C#.net","(?i)VBA","(?i)DevOps")

for(i in technical){
   technical_skills[i] <- +str_detect(apply(technical_skills, 1, paste0, collapse = " ", ignore_case = TRUE), technical[which(technical == i)])
}

colnames(technical_skills) <- c("Job_title", "Company", "Job_location_City", "Job_location_State","Seniority_level", "Employment_type","Job_function","Industries",                 "Job_description", "SPSS","Stata", "SAS","Scala","MATLAB", "C","C++", "Swift", "Julia","Hadoop","Spark","Pig","Tableau","REDCap", "Qualtrics", "Power BI", "Dedoose", "Atlas TI", "NVivo", "MPlus", "Mixor", "dbt", "BigQuery|big query", "Superset", "Baseten", "Airflow","ETL/ELT pipelines","Google Analytics", "Parse.ly", "Chartbeat","Excel", "Plotly", "Google Data Studio", "Looker","Spotfire","Smartsheet","Business Intelligence","C#|C#.net","VBA","DevOps")
```

### Programming Skills

```{r}
programming_skills <- tidied_Linkedin[c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description')]

programming <- c("(?i)python", "(?i)java", "(?i)javascript", "(?i)sql", "(?i)\\bR\\b", "(?i)stata","(?i)scala","(?i)matlab", "(?i)\\bC\\b","(?i)\\bC++\\b", "(?i)Swift", "(?i)Julia","(?i)Hadoop","(?i)Spark","(?i)Pig","\\bGo\\b","(?i)Kotlin","(?i)PHP","(?i)C#|C#.net","(?i)Ruby","(?i)TypeScript","(?i)HTML","(?i)CSS","(?i)NOSQL","(?i)Rust","(?i)Perl","(?i)Alteryx")

for(i in programming){
   programming_skills[i] <- +str_detect(apply(programming_skills, 1, paste0, collapse = " "), programming[which(programming == i)])
}

colnames(programming_skills) <- c("Job_title", "Company", "Job_location_City", "Job_location_State","Seniority_level", "Employment_type","Job_function","Industries",                 "Job_description","Python", "Java", "JavaScript", "SQL", "R", "Stata", "Scala","MATLAB", "C","C++", "Swift", "Julia","Hadoop","Spark","Pig","Go","Kotlin","PHP","C#|C#.net","Ruby","TypeScript","HTML","CSS","NOSQL","Rust","Perl","Alteryx")

# Source: https://www.simplilearn.com/best-programming-languages-start-learning-today-article

```

### Non-Technical Skills

```{r}
nontechnical_skills <- tidied_Linkedin[c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description')]

nontechnical <- c("(?i)communicate|communication", "(?i)critical thinking|critical-thinking", "(?i)problem solving|problem-solving", "(?i)business acumen", "(?i)storytell|data narrative", "(?i)adaptability","(?i)team player|team spirit", "(?i)product understanding","(?i)innovation","(?i)collaboration", "(?i)technical","(?i)visualization","(?i)attention","(?i)interpersonal","(?i)detail","(?i)presentation","(?i)multitask","(?i)decision making|decision-making","(?i)accuracy", "(?i)organization|organized","(?i)time management")

for(i in nontechnical){
   nontechnical_skills[i] <- +str_detect(apply(nontechnical_skills, 1, paste0, collapse = " "), nontechnical[which(nontechnical == i)])
}

colnames(nontechnical_skills) <- c("Job_title", "Company", "Job_location_City", "Job_location_State","Seniority_level", "Employment_type","Job_function","Industries",                 "Job_description","communication", "critical thinking", "problem-solving", "business acumen", "data narrative", "adaptability","team player", "product understanding","innovation","collaboration", "technical","visualization","attention","interpersonal","detail","presentation","multitask","decision-making","accuracy", "organization","time management")
# Source: https://www.simplilearn.com/best-programming-languages-start-learning-today-article

```

## Frequent Skills {.tabset}

### General Skills 
```{r, message=FALSE}
library(tidyverse)
general_long_table <- general_skills %>% 
  pivot_longer(cols = !c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description'), names_to = "skill", values_to = "count" )

frequent_general_skill <- general_long_table %>% 
  filter(count == 1)
frequent_general_skill <- frequent_general_skill  %>% 
  count(skill) %>% 
  mutate(percentage = (n / nrow(tidied_Linkedin))*100)

library(DT)
datatable(frequent_general_skill)
```


### Technical Skills
```{r}
library(tidyverse)
technical_long_table <- technical_skills %>% 
  pivot_longer(cols = !c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description'), names_to = "skill", values_to = "count" )

frequent_technical_skill <- technical_long_table %>% 
  filter(count == 1)
frequent_technical_skill <- frequent_technical_skill  %>% 
  count(skill) %>% 
  mutate(percentage = (n / nrow(tidied_Linkedin))*100)

library(DT)
datatable(frequent_technical_skill)
```

### Programming Languages

Based on 
```{r}
programming_long_table <- programming_skills %>% 
  pivot_longer(cols = !c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description'), names_to = "skill", values_to = "count" )

frequent_programming_skill <- programming_long_table %>% 
  filter(count == 1)
frequent_programming_skill <- frequent_programming_skill  %>% 
  count(skill) %>% 
  mutate(percentage = (n / nrow(tidied_Linkedin))*100)

datatable(frequent_programming_skill)
```
### Non-technical 
```{r}
nontechnical_long_table <- nontechnical_skills %>% 
  pivot_longer(cols = !c('Job_title','Company','Job_location_City','Job_location_State','Seniority_level','Employment_type','Job_function','Industries','Job_description'), names_to = "skill", values_to = "count" )

frequent_nontechnical_skill <- nontechnical_long_table %>% 
  filter(count == 1)
frequent_nontechnical_skill <- frequent_nontechnical_skill  %>% 
  count(skill) %>% 
  mutate(percentage = (n / nrow(tidied_Linkedin))*100)

datatable(frequent_nontechnical_skill)
```

# Data Visualization {.tabset}

## General Skills
```{r, warning=FALSE}
frequent_general_skill %>% 
    arrange(desc(percentage)) %>%
    slice(1:10) %>%
    ggplot(., aes(x = reorder(skill, percentage), y = percentage)) +
  geom_bar(stat = 'identity', skill= "blue" , fill = 'lightblue') +
  coord_flip() + ggtitle("Top 10 General Skills") +
  ylab("Percentage of Skill in Job Posting") +
  xlab("Skill")
```

## Technical Skills

```{r, warning=FALSE}
frequent_technical_skill %>% 
    arrange(desc(percentage)) %>%
    slice(1:10) %>%
    ggplot(., aes(x = reorder(skill, percentage), y = percentage)) +
  geom_bar(stat = 'identity', skill= "blue" , fill = 'lightblue') +
  coord_flip() + ggtitle("Top 10 Technical Skills") +
  ylab("Percentage of Skill in Job Posting") +
  xlab("Skill")
```

## Programming Languages

```{r, warning=FALSE}
frequent_programming_skill %>% 
    arrange(desc(percentage)) %>%
    slice(1:10) %>%
    ggplot(., aes(x = reorder(skill, percentage), y = percentage)) +
  geom_bar(stat = 'identity', skill= "blue" , fill = 'lightblue') +
  coord_flip() + ggtitle("Top 10 Programming Languages") +
  ylab("Percentage of Skill in Job Posting") +
  xlab("Skill")
```
## Non-Technical Skills
```{r, warning=FALSE}
frequent_nontechnical_skill %>% 
    arrange(desc(percentage)) %>%
    slice(1:10) %>%
    ggplot(., aes(x = reorder(skill, percentage), y = percentage)) +
  geom_bar(stat = 'identity', skill= "blue" , fill = 'lightblue') +
  coord_flip() + ggtitle("Top 10 Non-Technical Skills") +
  ylab("Percentage of Skill in Job Posting") +
  xlab("Skill")
```

## Analysis of job postings by State
```{r}
library(plotly)

#Filter out the rows with the city and state value "United States" because we don't want to report on those
Postings_by_state <- tidied_Linkedin %>% filter(Job_location_City != "United States")
Postings_by_state <- Postings_by_state %>% filter(Job_location_State != "United States")


# Count the job listings for the available states in the dataset
JobMapDF <- Postings_by_state %>% group_by(Job_location_State) %>% dplyr::summarize (n = n())

JobMapDF$hover <- with(JobMapDF, paste(Job_location_State, '<br>', "# of Jobs:", n))

g <- list(
  resolution = 110,
  showsubunits = T,
  subunitcolor = '#4b0082',
  scope = 'usa',
  showcountries = T,
  countrycolor = '#4b0082',
  projection = list(type = 'albers usa'),
  showlakes = TRUE,
  lakecolor = '#bb99ff',
  showland = TRUE,
  landcolor = toRGB("#eee6ff")
)

# plot the map
map <- plot_geo(JobMapDF, locationmode = 'USA-states') %>%
  add_trace(
    z = ~n, text = ~hover, locations = ~Job_location_State,
    color = ~n, colors = 'Purples'
  ) %>%
  colorbar(title = "Jobs Counts") %>%
  layout(
    title = 'Data Scientist Jobs Postings Analyzed by State',
    geo = g
  )
map

```

Sources

https://stackoverflow.com/questions/73640981/using-grep-on-multiple-columns-to-create-new-variable-in-r

https://stackoverflow.com/questions/44530029/how-to-ignore-case-when-using-str-detect
